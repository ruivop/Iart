{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning using AlphaZero methodology\n",
    "\n",
    "Please see https://applied-data.science/blog/how-to-build-your-own-alphazero-ai-using-python-and-keras/ for further notes on the codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First load the core libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# %matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from shutil import copyfile\n",
    "import random\n",
    "\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from game import Game, GameState\n",
    "from agent import Agent\n",
    "from memory import Memory\n",
    "from model import Residual_CNN\n",
    "from funcs import playMatches, playMatchesBetweenVersions\n",
    "\n",
    "import loggers as lg\n",
    "\n",
    "from settings import run_folder, run_archive_folder\n",
    "import initialise\n",
    "import pickle\n",
    "import importlib\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Now run this block to start the learning process\n",
    "\n",
    "This block loops for ever, continually learning from new game data.\n",
    "\n",
    "The current best model and memories are saved in the run folder so you can kill the process and restart from the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Desktop\\iart\\IartGit\\reiforcment\\DeepReinforcementLearning-master\\loss.py:16: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "\n",
      "\n",
      "ITERATION NUMBER 1\n",
      "BEST PLAYER VERSION 0\n",
      "SELF PLAYING 30 EPISODES...\n",
      "1 \n",
      "2 \n"
     ]
    }
   ],
   "source": [
    "lg.logger_main.info('=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*')\n",
    "lg.logger_main.info('=*=*=*=*=*=.      NEW LOG      =*=*=*=*=*')\n",
    "lg.logger_main.info('=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*')\n",
    "\n",
    "env = Game()\n",
    "\n",
    "# If loading an existing neural network, copy the config file to root\n",
    "if initialise.INITIAL_RUN_NUMBER != None:\n",
    "    copyfile(run_archive_folder + env.name + '/run' + str(initialise.INITIAL_RUN_NUMBER).zfill(4) + '/config.py', './config.py')\n",
    "\n",
    "import config\n",
    "\n",
    "######## LOAD MEMORIES IF NECESSARY ########\n",
    "\n",
    "if initialise.INITIAL_MEMORY_VERSION == None:\n",
    "    memory = Memory(config.MEMORY_SIZE)\n",
    "else:\n",
    "    print('LOADING MEMORY VERSION ' + str(initialise.INITIAL_MEMORY_VERSION) + '...')\n",
    "    memory = pickle.load( open( run_archive_folder + env.name + '/run' + str(initialise.INITIAL_RUN_NUMBER).zfill(4) + \"/memory/memory\" + str(initialise.INITIAL_MEMORY_VERSION).zfill(4) + \".p\",   \"rb\" ) )\n",
    "\n",
    "######## LOAD MODEL IF NECESSARY ########\n",
    "\n",
    "# create an untrained neural network objects from the config file\n",
    "current_NN = Residual_CNN(config.REG_CONST, config.LEARNING_RATE, (2,) + env.grid_shape,   env.action_size, config.HIDDEN_CNN_LAYERS)\n",
    "best_NN = Residual_CNN(config.REG_CONST, config.LEARNING_RATE, (2,) +  env.grid_shape,   env.action_size, config.HIDDEN_CNN_LAYERS)\n",
    "\n",
    "#If loading an existing neural netwrok, set the weights from that model\n",
    "if initialise.INITIAL_MODEL_VERSION != None:\n",
    "    best_player_version  = initialise.INITIAL_MODEL_VERSION\n",
    "    print('LOADING MODEL VERSION ' + str(initialise.INITIAL_MODEL_VERSION) + '...')\n",
    "    m_tmp = best_NN.read(env.name, initialise.INITIAL_RUN_NUMBER, best_player_version)\n",
    "    current_NN.model.set_weights(m_tmp.get_weights())\n",
    "    best_NN.model.set_weights(m_tmp.get_weights())\n",
    "#otherwise just ensure the weights on the two players are the same\n",
    "else:\n",
    "    best_player_version = 0\n",
    "    best_NN.model.set_weights(current_NN.model.get_weights())\n",
    "\n",
    "#copy the config file to the run folder\n",
    "copyfile('./config.py', run_folder + 'config.py')\n",
    "plot_model(current_NN.model, to_file=run_folder + 'models/model.png', show_shapes = True)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "######## CREATE THE PLAYERS ########\n",
    "\n",
    "current_player = Agent('current_player', env.state_size, env.action_size, config.MCTS_SIMS, config.CPUCT, current_NN)\n",
    "best_player = Agent('best_player', env.state_size, env.action_size, config.MCTS_SIMS, config.CPUCT, best_NN)\n",
    "#user_player = User('player1', env.state_size, env.action_size)\n",
    "iteration = 0\n",
    "\n",
    "while 1:\n",
    "\n",
    "    iteration += 1\n",
    "    importlib.reload(lg)\n",
    "    importlib.reload(config)\n",
    "    \n",
    "    print('ITERATION NUMBER ' + str(iteration))\n",
    "    \n",
    "    lg.logger_main.info('BEST PLAYER VERSION: %d', best_player_version)\n",
    "    print('BEST PLAYER VERSION ' + str(best_player_version))\n",
    "\n",
    "    ######## SELF PLAY ########\n",
    "    print('SELF PLAYING ' + str(config.EPISODES) + ' EPISODES...')\n",
    "    _, memory, _, _ = playMatches(best_player, best_player, config.EPISODES, lg.logger_main, turns_until_tau0 = config.TURNS_UNTIL_TAU0, memory = memory)\n",
    "    print('\\n')\n",
    "    \n",
    "    memory.clear_stmemory()\n",
    "    \n",
    "    if len(memory.ltmemory) >= config.MEMORY_SIZE:\n",
    "\n",
    "        ######## RETRAINING ########\n",
    "        print('RETRAINING...')\n",
    "        current_player.replay(memory.ltmemory)\n",
    "        print('')\n",
    "\n",
    "        if iteration % 5 == 0:\n",
    "            pickle.dump( memory, open( run_folder + \"memory/memory\" + str(iteration).zfill(4) + \".p\", \"wb\" ) )\n",
    "\n",
    "        lg.logger_memory.info('====================')\n",
    "        lg.logger_memory.info('NEW MEMORIES')\n",
    "        lg.logger_memory.info('====================')\n",
    "        \n",
    "        memory_samp = random.sample(memory.ltmemory, min(1000, len(memory.ltmemory)))\n",
    "        \n",
    "        for s in memory_samp:\n",
    "            current_value, current_probs, _ = current_player.get_preds(s['state'])\n",
    "            best_value, best_probs, _ = best_player.get_preds(s['state'])\n",
    "\n",
    "            lg.logger_memory.info('MCTS VALUE FOR %s: %f', s['playerTurn'], s['value'])\n",
    "            lg.logger_memory.info('CUR PRED VALUE FOR %s: %f', s['playerTurn'], current_value)\n",
    "            lg.logger_memory.info('BES PRED VALUE FOR %s: %f', s['playerTurn'], best_value)\n",
    "            lg.logger_memory.info('THE MCTS ACTION VALUES: %s', ['%.2f' % elem for elem in s['AV']]  )\n",
    "            lg.logger_memory.info('CUR PRED ACTION VALUES: %s', ['%.2f' % elem for elem in  current_probs])\n",
    "            lg.logger_memory.info('BES PRED ACTION VALUES: %s', ['%.2f' % elem for elem in  best_probs])\n",
    "            lg.logger_memory.info('ID: %s', s['state'].id)\n",
    "            lg.logger_memory.info('INPUT TO MODEL: %s', current_player.model.convertToModelInput(s['state']))\n",
    "\n",
    "            s['state'].render(lg.logger_memory)\n",
    "            \n",
    "        ######## TOURNAMENT ########\n",
    "        print('TOURNAMENT...')\n",
    "        scores, _, points, sp_scores = playMatches(best_player, current_player, config.EVAL_EPISODES, lg.logger_tourney, turns_until_tau0 = 0, memory = None)\n",
    "        print('\\nSCORES')\n",
    "        print(scores)\n",
    "        print('\\nSTARTING PLAYER / NON-STARTING PLAYER SCORES')\n",
    "        print(sp_scores)\n",
    "        #print(points)\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "        if scores['current_player'] > scores['best_player'] * config.SCORING_THRESHOLD:\n",
    "            best_player_version = best_player_version + 1\n",
    "            best_NN.model.set_weights(current_NN.model.get_weights())\n",
    "            best_NN.write(env.name, best_player_version)\n",
    "\n",
    "    else:\n",
    "        print('MEMORY SIZE: ' + str(len(memory.ltmemory)))\n",
    "        print('But it has to be: ' + str(config.MEMORY_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following panels are not involved in the learning process\n",
    "\n",
    "### Play matches between versions (use -1 for human player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from game import Game\n",
    "from funcs import playMatchesBetweenVersions\n",
    "import loggers as lg\n",
    "\n",
    "env = Game()\n",
    "playMatchesBetweenVersions(env, 1, 1, 1, 10, lg.logger_tourney, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass a particular game state through the neural network (setup below for Connect4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00000 | 0.00000 | 0.00778 | 0.00662 | 0.00679 | 0.00694 | 0.00000 | 0.00705 | 0.00702 | 0.00690 | 0.00739 | 0.00000 | 0.00697 | 0.00649 |  \n",
      "0.00000 | 0.00721 | 0.00702 | 0.00000 | 0.00711 | 0.00709 | 0.00684 | 0.00749 | 0.00000 | 0.00675 | 0.00754 | 0.00714 | 0.00636 | 0.00000 |  \n",
      "0.00000 | 0.00636 | 0.00669 | 0.00714 | 0.00679 | 0.00000 | 0.00747 | 0.00664 | 0.00725 | 0.00774 | 0.00000 | 0.00658 | 0.00714 | 0.00723 |  \n",
      "0.00000 | 0.00694 | 0.00000 | 0.00719 | 0.00681 | 0.00680 | 0.00683 | 0.00000 | 0.00697 | 0.00763 | 0.00663 | 0.00765 | 0.00000 | 0.00699 |  \n",
      "0.00000 | 0.00688 | 0.00727 | 0.00741 | 0.00000 | 0.00663 | 0.00667 | 0.00735 | 0.00721 | 0.00000 | 0.00709 | 0.00735 | 0.00728 | 0.00667 |  \n",
      "0.00000 | 0.00000 | 0.00727 | 0.00705 | 0.00685 | 0.00685 | 0.00000 | 0.00701 | 0.00650 | 0.00687 | 0.00652 | 0.00000 | 0.00709 | 0.00638 |  \n",
      "0.00000 | 0.00000 | 0.00748 | 0.00000 | 0.00644 | 0.00743 | 0.00723 | 0.00685 | 0.00000 | 0.00735 | 0.00687 | 0.00720 | 0.00807 | 0.00000 |  \n",
      "0.00000 | 0.00000 | 0.00695 | 0.00706 | 0.00657 | 0.00000 | 0.00635 | 0.00687 | 0.00730 | 0.00731 | 0.00000 | 0.00672 | 0.00708 | 0.00686 |  \n",
      "0.00714 | 0.00000 | 0.00000 | 0.00630 | 0.00693 | 0.00648 | 0.00705 | 0.00000 | 0.00730 | 0.00671 | 0.00711 | 0.00678 | 0.00000 | 0.00679 |  \n",
      "0.00000 | 0.00000 | 0.00730 | 0.00713 | 0.00000 | 0.00732 | 0.00727 | 0.00699 | 0.00689 | 0.00000 | 0.00731 | 0.00716 | 0.00690 | 0.00735 |  \n",
      "0.00000 | 0.00000 | 0.00677 | 0.00765 | 0.00721 | 0.00607 | 0.00000 | 0.00698 | 0.00687 | 0.00695 | 0.00766 | 0.00000 | 0.00668 | 0.00690 |  \n",
      "0.00000 | 0.00629 | 0.00696 | 0.00000 | 0.00688 | 0.00626 | 0.00667 | 0.00684 | 0.00000 | 0.00714 | 0.00753 | 0.00750 | 0.00665 | 0.00000 |  \n",
      "0.00000 | 0.00754 | 0.00702 | 0.00709 | 0.00667 | 0.00000 | 0.00653 | 0.00738 | 0.00640 | 0.00783 | 0.00000 | 0.00681 | 0.00729 | 0.00693 |  \n",
      "0.00652 | 0.00684 | 0.00000 | 0.00638 | 0.00686 | 0.00694 | 0.00739 | 0.00000 | 0.00622 | 0.00753 | 0.00721 | 0.00675 | 0.00000 | 0.00704 |  \n"
     ]
    }
   ],
   "source": [
    "gs = GameState(np.array([\n",
    "1, -1, 0, 0, 0, 0, 1, 0, 0, 0, 0, -1, 0, 0,\n",
    "1, 0, 0, 1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 1,\n",
    "1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
    "1, 0, -1, 0, 0, 0, 0, 1, 0, 0, 0, 0, -1, 0,\n",
    "1, 0, 0, 0, 1, 0, 0, 0, 0, -1, 0, 0, 0, 0,\n",
    "1, 1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 1, 0, 0,\n",
    "1, 1, 0, -1, 0, 0, 0, 0, 1, 0, 0, 0, 0, -1,\n",
    "-1, 1, 0, 0, 0, 1, 0, 0, 0, 0, -1, 0, 0, 0,\n",
    "0, 1, 1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 1, 0,\n",
    "1, 1, 0, 0, -1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "1, -1, 0, 0, 0, 0, 1, 0, 0, 0, 0, -1, 0, 0,\n",
    "1, 0, 0, 1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 1,\n",
    "1, 0, 0, 0, 0, -1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
    "0, 0, -1, 0, 0, 0, 0, 1, 0, 0, 0, 0, -1, 0\n",
    "]), 1)\n",
    "\n",
    "preds = current_player.get_preds(gs)\n",
    "\n",
    "#print(preds[1])\n",
    "for r in range(14):\n",
    "\tfor x in preds[1][14*r : (14*r + 14)]:\n",
    "\t\tprint(\"%1.4f\" % x, end=\" | \")\n",
    "\tprint(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the layers of the current neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_player.model.viewLayers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output a diagram of the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(current_NN.model, to_file=run_folder + 'models/model.png', show_shapes = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
